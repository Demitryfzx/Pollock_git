{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "client = MongoClient(\"mongodb://intern:password0711@161.117.176.172:27018/intern_tmp\")\n",
    "\n",
    "db = client['intern_tmp']\n",
    "collection = db['rate_release_dates']\n",
    "\n",
    "# data = {\n",
    "#     \"date\": datetime(2024, 6, 14),\n",
    "#     \"instrument_code\": \"BOJDTR Index\",\n",
    "#     \"description\": \"BOJ rate release\",\n",
    "#     \"timezone\": \"Japan\"\n",
    "# }\n",
    "\n",
    "# collection.insert_one(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Ticker doesn't provide meeting dates\n",
      "DEBRDISC generated an exception: 'NoneType' object is not iterable\n",
      "This Ticker doesn't provide meeting dates\n",
      "CHLR12M generated an exception: 'NoneType' object is not iterable\n",
      "This Ticker doesn't provide meeting dates\n",
      "EGBRDR generated an exception: 'NoneType' object is not iterable\n",
      "This Ticker doesn't provide meeting dates\n",
      "HKBASE generated an exception: 'NoneType' object is not iterable\n",
      "This Ticker doesn't provide meeting dates\n",
      "QAIRONLR generated an exception: 'NoneType' object is not iterable\n",
      "This Ticker doesn't provide meeting dates\n",
      "This Ticker doesn't provide meeting dates\n",
      "CUAEBASE generated an exception: 'NoneType' object is not iterable\n",
      "ICBRANN generated an exception: 'NoneType' object is not iterable\n",
      "This Ticker doesn't provide meeting dates\n",
      "SRREPO generated an exception: 'NoneType' object is not iterable\n",
      "This Ticker doesn't provide meeting dates\n",
      "VNREFINC generated an exception: 'NoneType' object is not iterable\n"
     ]
    }
   ],
   "source": [
    "from Big_Date_API import *\n",
    "\n",
    "historical_dates = obtain_all_historical_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# historical_dates = {\n",
    "#     'ticker1': [\n",
    "#         {\"date\": '2023-01-01', \"instrument code\": \"code1\", \"description\": \"bank1 rate release\", \"timezone\": \"UTC\"},\n",
    "#         {\"date\": '2023-01-02', \"instrument code\": None, \"description\": \"bank2 rate release\", \"timezone\": \"UTC\"},\n",
    "#     ],\n",
    "#     'ticker2': [\n",
    "#         {\"date\": None, \"instrument code\": \"code2\", \"description\": \"bank3 rate release\", \"timezone\": \"UTC\"},\n",
    "#         {\"date\": '2023-01-03', \"instrument code\": \"code3\", \"description\": \"bank4 rate release\", \"timezone\": \"UTC\"},\n",
    "#     ]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# historical_dates = {\n",
    "#     'ticker1': [\n",
    "#         {\"date\": '2023-01-01', \"instrument code\": \"code1\", \"description\": \"bank1 rate release\", \"timezone\": \"UTC\"},\n",
    "#         {\"date\": '2023-01-02', \"instrument code\": None, \"description\": \"bank2 rate release\", \"timezone\": \"UTC\"},\n",
    "#     ],\n",
    "#     'ticker2': [\n",
    "#         {\"date\": None, \"instrument code\": \"code2\", \"description\": \"bank3 rate release\", \"timezone\": \"UTC\"},\n",
    "#         {\"date\": '2023-01-03', \"instrument code\": \"code3\", \"description\": \"bank4 rate release\", \"timezone\": \"UTC\"},\n",
    "#     ]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the actual release time\n",
    "release_time_df = pd.read_csv('./rate_released_time.csv', header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = []\n",
    "\n",
    "for ticker, entries in historical_dates.items():\n",
    "    for entry in entries:\n",
    "        if None in entry.values():\n",
    "            print(f\"Invalid entry for {ticker}: {entry}\")\n",
    "        else:\n",
    "            valid_data.append({\n",
    "                \"ticker\": ticker,\n",
    "                \"date\": entry[\"date\"],\n",
    "                \"country\": entry[\"country\"],\n",
    "                \"description\": entry[\"description\"],\n",
    "                \"timezone\": entry[\"timezone\"]\n",
    "            })\n",
    "\n",
    "df = pd.DataFrame(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# release_time_df['zone'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timezone_mappings = {\n",
    "#     'CST': 'America/Chicago',      # Central Standard Time\n",
    "#     'EDT': 'America/New_York',     # Eastern Daylight Time\n",
    "#     'AEST': 'Australia/Sydney',    # Australian Eastern Standard Time\n",
    "#     'BRT': 'America/Sao_Paulo',    # Brasilia Time\n",
    "#     'CET': 'Europe/Paris',         # Central European Time\n",
    "#     'GMT': 'Etc/GMT',              # Greenwich Mean Time\n",
    "#     'PHT': 'Asia/Manila',          # Philippine Time\n",
    "#     'IST': 'Asia/Kolkata',         # India Standard Time\n",
    "#     'NZST': 'Pacific/Auckland',    # New Zealand Standard Time\n",
    "#     'MST': 'America/Denver',       # Mountain Standard Time\n",
    "#     'KST': 'Asia/Seoul',           # Korea Standard Time\n",
    "#     'SAST': 'Africa/Johannesburg', # South Africa Standard Time\n",
    "#     'ET': 'America/New_York',      # Eastern Time (can be EST or EDT)\n",
    "#     'MSK': 'Europe/Moscow',        # Moscow Time\n",
    "#     'HKT': 'Asia/Hong_Kong',       # Hong Kong Time\n",
    "#     'SGT': 'Asia/Singapore'        # Singapore Time\n",
    "# }\n",
    "\n",
    "# hong_kong_tz = pytz.timezone('Asia/Hong_Kong')\n",
    "\n",
    "# release_time_dict = {}\n",
    "# time_pattern = re.compile(r'^\\d{4}$')\n",
    "\n",
    "\n",
    "# for country, row in release_time_df.iterrows():\n",
    "#     if pd.isna(row['zone']) or pd.isna(row['time']):\n",
    "#         continue\n",
    "\n",
    "#     if not time_pattern.match(row['time']):\n",
    "#         continue\n",
    "    \n",
    "#     time_str = row['time']\n",
    "#     time_obj = datetime.strptime(time_str, '%H%M')\n",
    "    \n",
    "#     original_tz_name = timezone_mappings.get(row['zone'].strip())\n",
    "#     if original_tz_name is None:\n",
    "#         raise ValueError(f\"Unknown {row['zone']}\")\n",
    "    \n",
    "#     original_tz = pytz.timezone(original_tz_name)\n",
    "    \n",
    "#     time_obj = original_tz.localize(time_obj)\n",
    "    \n",
    "#     hk_time_obj = time_obj.astimezone(hong_kong_tz)\n",
    "#     hk_time_str = hk_time_obj.strftime('%H:%M')\n",
    "    \n",
    "#     release_time_dict[country] = hk_time_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "release_time_dict = {}\n",
    "time_pattern = re.compile(r'^\\d{4}$')\n",
    "\n",
    "for country, row in release_time_df.iterrows():\n",
    "    if pd.isna(row['time']):\n",
    "        continue\n",
    "\n",
    "    if not time_pattern.match(row['time']):\n",
    "        continue\n",
    "    \n",
    "    time_str = row['time']\n",
    "    time_obj = datetime.datetime.strptime(time_str, '%H%M')\n",
    "    \n",
    "    release_time_dict[country] = time_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Taiwan': datetime.datetime(1900, 1, 1, 16, 30), 'United States': datetime.datetime(1900, 1, 1, 14, 0), 'Australia': datetime.datetime(1900, 1, 1, 14, 30), 'Brazil': datetime.datetime(1900, 1, 1, 18, 30), 'Norway': datetime.datetime(1900, 1, 1, 10, 0), 'Switzerland': datetime.datetime(1900, 1, 1, 9, 30), 'United Kingdom': datetime.datetime(1900, 1, 1, 12, 0), 'Philippines': datetime.datetime(1900, 1, 1, 15, 0), 'Sweden': datetime.datetime(1900, 1, 1, 9, 30), 'Turkey': datetime.datetime(1900, 1, 1, 14, 0), 'Israel': datetime.datetime(1900, 1, 1, 18, 0), 'New Zealand': datetime.datetime(1900, 1, 1, 14, 0), 'Malaysia': datetime.datetime(1900, 1, 1, 15, 0), 'South Korea': datetime.datetime(1900, 1, 1, 10, 0), 'South Africa': datetime.datetime(1900, 1, 1, 15, 0), 'Canada': datetime.datetime(1900, 1, 1, 10, 0), 'Russia': datetime.datetime(1900, 1, 1, 13, 30), 'India': datetime.datetime(1900, 1, 1, 10, 0), 'Hong Kong': datetime.datetime(1900, 1, 1, 8, 0)}\n"
     ]
    }
   ],
   "source": [
    "print(release_time_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def historical_data_insert(df, \n",
    "                           db_name, \n",
    "                           collection_name, \n",
    "                           mongo_uri):\n",
    "    required_columns = ['date', 'country', 'description', 'timezone']\n",
    "    for col in required_columns:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"DataFrame Loss the Column: {col}\")\n",
    "    \n",
    "    df['date'] = df['date'].apply(lambda x: datetime.datetime.combine(x, datetime.datetime.min.time()) if isinstance(x, datetime.date) else x)\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        country = row['country']\n",
    "        if (country in (release_time_dict.keys())):\n",
    "            hour, minute = release_time_dict[country].hour, release_time_dict[country].minute\n",
    "            df.loc[idx, 'date'] = df.loc[idx, 'date'] + pd.Timedelta(hours = hour, minutes = minute)\n",
    "\n",
    "    data_to_insert = df.to_dict(orient='records')\n",
    "\n",
    "    \n",
    "    client = MongoClient(mongo_uri)\n",
    "    db = client[db_name]\n",
    "    collection = db[collection_name]\n",
    "    result = collection.insert_many(data_to_insert)\n",
    "\n",
    "    print(\"Successful Insertion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = historical_data_insert(df, \n",
    "#                        'intern_tmp', \n",
    "#                        'rate_release_dates', \n",
    "#                        mongo_uri=\"mongodb://intern:password0711@161.117.176.172:27018/intern_tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful Insertion\n"
     ]
    }
   ],
   "source": [
    "historical_data_insert(df, \n",
    "                       'intern_tmp', \n",
    "                       'rate_release_dates', \n",
    "                       mongo_uri=\"mongodb://intern:password0711@161.117.176.172:27018/intern_tmp\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
